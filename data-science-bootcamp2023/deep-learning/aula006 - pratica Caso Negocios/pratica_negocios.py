# -*- coding: utf-8 -*-
"""pratica_Negocios.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E-CIlTlFUYy5z2bmrGNYSn2YLxXxd5KK
"""

'''
Plano de ação do caso de negócios
1. Pré-processamento dos dados
2. Criar o algortimo de ML
'''

# Bibliotecas
import numpy as np
from sklearn import preprocessing
import tensorflow as tf

# Datset
raw_csv_data = np.loadtxt("Audiobooks_data.csv", delimiter=",")
unscaled_inputs_all = raw_csv_data[:,1:-1]
targets_all = raw_csv_data[:,-1]

# Balanceamento do Dataset
num_one_targets = int(np.sum(targets_all))
zero_targets_counter = 0
indices_to_remove = []

for i in range(targets_all.shape[0]):
  if targets_all[i] == 0:
    zero_targets_counter += 1
    if zero_targets_counter > num_one_targets:
      indices_to_remove.append(i)

unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis = 0)
targets_equal_priors = np.delete(targets_all, indices_to_remove, axis = 0)

# Padronização do Dataset
scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)

# "Embaralhamento" do Dataset
shuffled_indices = np.arange(scaled_inputs.shape[0])
np.random.shuffle(shuffled_indices)
shuffled_inputs = scaled_inputs[shuffled_indices]
shuffled_targets = targets_equal_priors[shuffled_indices]

# Divisão do Dataset em Treinamento, Validação e Teste
samples_count = shuffled_inputs.shape[0]
train_sample_count = int(0.8 * samples_count)
validation_sample_count = int(0.1 * samples_count)
test_sample_count = samples_count - train_sample_count - validation_sample_count

train_inputs = shuffled_inputs[:train_sample_count]
train_targets = shuffled_targets[:train_sample_count]

validation_inputs = shuffled_inputs[train_sample_count:train_sample_count+validation_sample_count]
validation_targets = shuffled_targets[train_sample_count:train_sample_count+validation_sample_count]

test_inputs = shuffled_inputs[train_sample_count+validation_sample_count:]
test_targets = shuffled_targets[train_sample_count+validation_sample_count:]

print(f"Treinamento: {np.sum(train_targets)}, {train_sample_count}, {np.sum(train_targets) / train_sample_count}")
print(f"Validação: {np.sum(validation_targets)}, {validation_sample_count}, {np.sum(validation_targets) / validation_sample_count}")
print(f"Teste: {np.sum(test_targets)}, {test_sample_count}, {np.sum(test_targets) / test_sample_count}")

# Salvando o Dataset no Formato .npz
np.savez("Audiobooks_data_train", inputs=train_inputs, targets=train_targets)
np.savez("Audiobooks_data_validation", inputs=validation_inputs, targets=validation_targets)
np.savez("Audiobooks_data_test", inputs=test_inputs, targets=test_targets)

# Definição do Modelo
# Entradas: 10; Saídas: 2; Camadas Ocultas: 2; Comprimento das Camadas: 50
npz = np.load("Audiobooks_data_train.npz")
train_inputs = npz["inputs"].astype(np.float64)
train_targets = npz["targets"].astype(np.int64)

npz = np.load("Audiobooks_data_validation.npz")
validation_inputs, validation_targets = npz["inputs"].astype(np.float64), npz["targets"].astype(np.int64)

npz = np.load("Audiobooks_data_test.npz")
test_inputs, test_targets = npz["inputs"].astype(np.float64), npz["targets"].astype(np.int64)

# Definição do Modelo (continuação)
input_size = 10
output_size = 2
hidden_layer_size = 50

model = tf.keras.Sequential([
                            tf.keras.layers.Dense(hidden_layer_size, activation="relu"),
                            tf.keras.layers.Dense(hidden_layer_size, activation="relu"),
                            tf.keras.layers.Dense(hidden_layer_size, activation="softmax")
                            ])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

batch_size = 100
max_epochs = 100
early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)   # objeto de parada precoce

model.fit(train_inputs,
          train_targets,
          batch_size=batch_size,
          epochs=max_epochs,
          callbacks=[early_stopping],
          validation_data=[validation_inputs, validation_targets],
          verbose=2)

# Testando o Modelo
test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)
print(f"Test loss: {test_loss}. Test accuracy: {test_accuracy}")